# -*- coding: utf-8 -*-
"""ML2023Spring_HW8.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1iqvGMVMkmTynKI8UQWaYeXxdQXeO7CKM

# **Homework 8 - Anomaly Detection**

If there are any questions, please contact mlta-2023-spring@googlegroups.com

Slide:    [Link](https://docs.google.com/presentation/d/18LkR8qulwSbi3SVoLl1XNNGjQQ_qczs_35lrJWOmHCk/edit?usp=sharing) Kaggle: [Link](https://www.kaggle.com/t/c76950cc460140eba30a576ca7668d28)

"""

# Import packages
import random
import numpy as np
import torch
from torch import nn
from torch.utils.data import DataLoader, RandomSampler, TensorDataset
import torchvision.transforms as transforms
from torchvision.models import resnet18
from torch.autograd import Variable
from torch.optim import AdamW
from  tqdm import tqdm, trange
import os

def same_seeds(seed):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed(seed)
        torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.benchmark = False
    torch.backends.cudnn.deterministic = True

"""# Autoencoder

# Models & loss
"""

class fcn_autoencoder(nn.Module):
    def __init__(self):
        super(fcn_autoencoder, self).__init__()
        self.encoder = nn.Sequential(
            nn.Linear(64 * 64 * 3, 512),
            nn.ReLU(),
            nn.Linear(512, 256),
            nn.ReLU(),
            nn.Linear(256, 80),
        )    # Hint: dimension of latent space can be adjusted
        
        self.decoder = nn.Sequential(
            nn.Linear(80, 256),
            nn.ReLU(),
            nn.Linear(256, 512),
            nn.ReLU(),
            nn.Linear(512, 64 * 64 * 3),

            nn.Tanh()
        )

    def forward(self, x):
        x = self.encoder(x)
        x = self.decoder(x)
        return x

class conv_autoencoder(nn.Module):
    def __init__(self):
        super(conv_autoencoder, self).__init__()
        self.encoder = nn.Sequential(
            nn.Conv2d(3, 12, 4, stride=2, padding=1),
            nn.BatchNorm2d(12),
            nn.ReLU(),

            nn.Conv2d(12, 24, 4, stride=2, padding=1),
            nn.BatchNorm2d(24),
            nn.ReLU(),

            nn.Conv2d(24, 48, 4, stride=2, padding=1),
            nn.BatchNorm2d(48),
            nn.ReLU(),

            nn.Conv2d(48, 96, 4, stride=2, padding=1),
            nn.BatchNorm2d(96),
            nn.ReLU(),

            nn.Conv2d(96, 192, 4, stride=2, padding=1),
            nn.BatchNorm2d(192),
            nn.ReLU(),
        )   # Hint:  dimension of latent space can be adjusted
        self.decoder = nn.Sequential(
            nn.ConvTranspose2d(192, 96, 4, stride=2, padding=1),
            nn.BatchNorm2d(96),
            nn.ReLU(),

            nn.ConvTranspose2d(96, 48, 4, stride=2, padding=1),
            nn.BatchNorm2d(48),
            nn.ReLU(),

            nn.ConvTranspose2d(48, 24, 4, stride=2, padding=1),
            nn.BatchNorm2d(24),
            nn.ReLU(),

            nn.ConvTranspose2d(24, 12, 4, stride=2, padding=1),
            nn.BatchNorm2d(12),
            nn.ReLU(),

            nn.ConvTranspose2d(12, 3, 4, stride=2, padding=1),
            nn.BatchNorm2d(3),
            nn.Tanh(),
        )

    def forward(self, x):
        x = self.encoder(x)
        x = self.decoder(x)
        return x

class resnet_autoencoder(nn.Module):
    def __init__(self):
        super(resnet_autoencoder, self).__init__()
        # Encoder
        resnet = resnet18(weights=None)
        self.encoder = resnet = nn.Sequential(*list(resnet.children())[:-1])

        # Decoder
        self.decoder = nn.Sequential(
            nn.ConvTranspose2d(512, 256, 4, stride=2, padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(),

            nn.ConvTranspose2d(256, 128, 4, stride=2, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(),

            nn.ConvTranspose2d(128, 64, 4, stride=2, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(),

            nn.ConvTranspose2d(64, 32, 4, stride=2, padding=1),
            nn.BatchNorm2d(32),
            nn.ReLU(),

            nn.ConvTranspose2d(32, 16, 4, stride=2, padding=1),
            nn.BatchNorm2d(16),
            nn.ReLU(),

            nn.ConvTranspose2d(16, 3, 4, stride=2, padding=1),
            nn.BatchNorm2d(3),
            nn.Tanh(),
        )

    def forward(self, x):
        x = self.encoder(x)
        x = self.decoder(x)

        return x

class VAE(nn.Module):
    def __init__(self):
        super(VAE, self).__init__()
        self.encoder = nn.Sequential(
            nn.Conv2d(3, 12, 4, stride=2, padding=1),
            nn.ReLU(),

            nn.Conv2d(12, 24, 4, stride=2, padding=1),
            nn.ReLU(),

            nn.Conv2d(24, 48, 4, stride=2, padding=1),
            nn.ReLU(),

            nn.Conv2d(48, 96, 4, stride=2, padding=1),
            nn.ReLU(),
        )
        self.enc_out_1 = nn.Sequential(
            nn.Conv2d(96, 192, 4, stride=2, padding=1),
            nn.ReLU(),
        )
        self.enc_out_2 = nn.Sequential(
            nn.Conv2d(96, 192, 4, stride=2, padding=1),
            nn.ReLU(),
        )
        # Hint: can add more layers to encoder and decoder
        self.decoder = nn.Sequential(
            nn.ConvTranspose2d(96, 48, 4, stride=2, padding=1),
            nn.ReLU(),

            nn.ConvTranspose2d(48, 24, 4, stride=2, padding=1),
            nn.ReLU(),

            nn.ConvTranspose2d(24, 12, 4, stride=2, padding=1),
            nn.ReLU(),

            nn.ConvTranspose2d(12, 3, 4, stride=2, padding=1),
            nn.Tanh(),
        )

    def encode(self, x):
        h1 = self.encoder(x)
        return self.enc_out_1(h1), self.enc_out_2(h1)

    def reparametrize(self, mu, logvar):
        std = logvar.mul(0.5).exp_()
        if torch.cuda.is_available():
            eps = torch.cuda.FloatTensor(std.size()).normal_()
        else:
            eps = torch.FloatTensor(std.size()).normal_()
        eps = Variable(eps)
        return eps.mul(std).add_(mu)

    def decode(self, z):
        return self.decoder(z)

    def forward(self, x):
        mu, logvar = self.encode(x)
        z = self.reparametrize(mu, logvar)
        return self.decode(z), mu, logvar

class classifier(nn.Module):
    def __init__(self, num_class=2):
        super(classifier, self).__init__()

        self.fc = nn.Sequential(
            nn.Linear(64 * 64 * 3, 512),
            nn.Linear(512, 64),
            nn.Linear(64, num_class),
        )

    def forward(self, x):
        x = x.view(x.size()[0], -1)
        return self.fc(x)
    
class multi_encoder_autoencoder(nn.Module):
    def __init__(self):
        super(multi_encoder_autoencoder, self).__init__()
        self.fcn = fcn_autoencoder()
        self.resnet = resnet_autoencoder()
        self.vae = VAE()

        self.decoder = nn.Sequential(
            nn.Linear(80 + 512 + 768, 4096),
            nn.ReLU(),
            nn.Linear(4096, 64 * 64 * 3),

            nn.Tanh()
        )

        self.classifier = classifier()
        
    def forward(self, x):
        x_flat = x.view(x.shape[0], -1)
        fcn_embedding = self.fcn.encoder(x_flat)

        resnet_embedding = self.resnet.encoder(x)
        resnet_embedding = torch.flatten(resnet_embedding, start_dim=1)

        mu, logvar = self.vae.encode(x)
        vae_embedding = self.vae.reparametrize(mu, logvar)
        vae_embedding = torch.flatten(vae_embedding, start_dim=1)

        embedding = torch.cat([fcn_embedding, resnet_embedding, vae_embedding], dim=1)

        real = self.decoder(embedding)

        mean = torch.mean(embedding)
        std = torch.std(embedding)

        random_noise = torch.randn_like(embedding) * std + mean
        fake = self.decoder(random_noise)
        
        real, fake = real.reshape(-1, 3, 64, 64), fake.reshape(-1, 3, 64, 64)

        real_logits = self.classifier(real)
        fake_logits = self.classifier(fake)

        return real, torch.cat((real_logits, fake_logits), dim=0)
    
def loss_vae(recon_x, x, mu, logvar, criterion):
    """
    recon_x: generating images
    x: origin images
    mu: latent mean
    logvar: latent log variance
    """
    mse = criterion(recon_x, x)
    KLD_element = mu.pow(2).add_(logvar.exp()).mul_(-1).add_(1).add_(logvar)
    KLD = torch.sum(KLD_element).mul_(-0.5)
    return mse + KLD

"""# Dataset module

Module for obtaining and processing data. The transform function here normalizes image's pixels from [0, 255] to [-1.0, 1.0].

"""

class CustomTensorDataset(TensorDataset):
    """TensorDataset with support of transforms.
    """
    def __init__(self, tensors):
        self.tensors = tensors
        if tensors.shape[-1] == 3:
            self.tensors = tensors.permute(0, 3, 1, 2)
        
        self.transform = transforms.Compose([
          transforms.Lambda(lambda x: x.to(torch.float32)),
          transforms.Lambda(lambda x: 2. * x/255. - 1.),
        ])
        
    def __getitem__(self, index):
        x = self.tensors[index]
        
        if self.transform:
            # mapping images to [-1.0, 1.0]
            x = self.transform(x)

        return x

    def __len__(self):
        return len(self.tensors)

"""## Random seed
Set the random seed to a certain value for reproducibility.
"""

same_seeds(2023)

"""# Training

## Configuration
"""

# Training hyperparameters
num_epochs = 1000
batch_size = 400 # Hint: batch size may be lower
learning_rate = 1e-3
weight_decay = 1e-4
patience = 10

# Model
model_type = 'fcn'   # selecting a model type from {'cnn', 'fcn', 'vae', 'resnet', 'multi'}
model_classes = {
    'fcn': fcn_autoencoder(),
    'cnn': conv_autoencoder(),
    'resnet': resnet_autoencoder(),
    'vae': VAE(),
    'multi': multi_encoder_autoencoder()
}
model = model_classes[model_type].cuda()

# Loss and optimizer
if model_type in ['multi']:
    criterion = nn.CrossEntropyLoss()
else:
    criterion = nn.MSELoss()
optimizer = AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)

model_save_dir = 'ckpt'
if not os.path.exists(model_save_dir):
    os.mkdir(model_save_dir)

def main():
    """# Loading data"""

    train = np.load('data/trainingset.npy', allow_pickle=True)

    print(f'Training dataset size: {train.shape}')
    
    # Build training dataloader
    x = torch.from_numpy(train)
    train_dataset = CustomTensorDataset(x)

    train_sampler = RandomSampler(train_dataset)
    train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=batch_size)

    """## Training loop"""

    best_loss = np.inf
    model.train()
    stale = 0

    for epoch in trange(num_epochs):
        tot_loss = list()
        for data in train_dataloader:

            # ===================loading=====================
            img = data.float().cuda()
            if model_type in ['fcn']:
                img = img.view(img.shape[0], -1)

            # ===================forward=====================
            if model_type in ['multi']:
                output, logits = model(img)
                gt = torch.zeros(logits.shape[0], dtype=torch.long)
                gt[(logits.shape[0]//2):] = 1
                loss = criterion(logits, gt.cuda())

            else:
                output = model(img)
                if model_type in ['vae']:
                    loss = loss_vae(output[0], img, output[1], output[2], criterion)
                else:
                    loss = criterion(output, img)

            tot_loss.append(loss.item())
            # ===================backward====================
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
        # ===================save_best====================
        mean_loss = np.mean(tot_loss)
        if np.isnan(mean_loss):
            print('Loss equal to nan. Break.')
            break
        if mean_loss < best_loss:
            stale = 0
            best_loss = mean_loss
            torch.save(model, f'{model_save_dir}/best_model_{model_type}.pt')
        # ===================log========================
            print(f'epoch: {epoch + 1:.0f}/{num_epochs:.0f}, loss: {mean_loss:.4f} -> best (saved)')
        else:
            stale += 1
            print(f'epoch: {epoch + 1:.0f}/{num_epochs:.0f}, loss: {mean_loss:.4f}')
            if stale >= patience:
                print(f'No improve for {patience} epochs. Early stop.')
                break
        # ===================save_last========================
        torch.save(model, f'{model_save_dir}/last_model_{model_type}.pt')

if __name__ == "__main__":
    main()